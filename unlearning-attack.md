### ğŸ“š Unlearning Attack è®ºæ–‡åˆ†ç±»æ€»è§ˆè¡¨

| è®ºæ–‡æ ‡é¢˜                                                     | ä½œè€…                                                         |       ä¼šè®®/å¹´ä»½        | é—å¿˜ç±»å‹                                | æ”»å‡»åœºæ™¯ (Attack Scenario)                                   | æ”»å‡»ç±»å‹ (Attack Type)                       | å¨èƒæ¨¡å‹ (Threat Model)                                      | å…³é”®æ–¹æ³•/è´¡çŒ®ç®€è¿°                                            | æ˜¯å¦å¼€æº                                                   |
| ------------------------------------------------------------ | ------------------------------------------------------------ | :--------------------: | --------------------------------------- | ------------------------------------------------------------ | -------------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ | ---------------------------------------------------------- |
| `Paper Title`                                                | `Author et al.`                                              |      `Conf. Year`      | `exact/approximate unlearning`          | `e.g., å•æ ·æœ¬é—å¿˜ / è”é‚¦é—å¿˜ / åœ¨çº¿å­¦ä¹ `                     | `e.g., MIA / æ¨¡å‹æå– / é—å¿˜ç»•è¿‡ / å·®åˆ†æ”»å‡»` | `e.g., é»‘ç›’ / ç™½ç›’ / ç°ç›’`                                   | ç®€è¦æè¿°å…¶æ”»å‡»æœºåˆ¶æˆ–åˆ›æ–°ç‚¹ï¼ˆå¦‚ï¼šâ€œæå‡ºé’ˆå¯¹SISAæ¡†æ¶çš„MIAå˜ä½“â€ï¼‰ | âœ… / âŒ                                                      |
| `A Duty to Forget, a Right to be Assured? Exposing  Vulnerabilities in Machine Unlearning Services` | `Hongsheng Huâˆ—, Shuo WangÂ§âˆ—, Jiamin Changâ€ âˆ—, Haonan Zhongâ€ âˆ—, Ruoxi Sunâˆ—, Shuang Haoâ€¡, Haojin ZhuÂ§, and Minhui Xueâˆ—` |      `NDSS 2024`       | `gradient-based approximate unlearning` | `æäº¤æ¶æ„çš„é—å¿˜ç”³è¯·ï¼ˆä¿®æ”¹æ•°æ®ï¼‰è¯±å¯¼æœåŠ¡å™¨æ¨¡å‹çš„ä¸¥é‡æ€§èƒ½ä¸‹é™` | `æ•°æ®ä¸­æ¯’æ”»å‡»`                               | `é»‘ç›’(æäº¤æ•°æ®æ ·æœ¬xæ¥æŸ¥è¯¢æ¨¡å‹ï¼Œå¹¶è·å¾—æ¦‚ç‡å‘é‡Yï¼Œä½†æ— æ³•çŸ¥é“æ¨¡å‹çš„å‚æ•°å’Œç»“æ„)ä¸çŸ¥é“unlearnngç®—æ³•` | `åˆ©ç”¨CW-attackç”Ÿäº§å¯¹æŠ—æ ·æœ¬`                                  | ` https://github.com/ TASI-LAB/Over-unlearning`            |
| `Backdoor Attacks via Machine Unlearning`                    | `Zihao Liu1, Tianhao Wang2, Mengdi Huai1, Chenglin Miao1`    |      `AAAI 2024`       | `exact && approximate unlearning`       | `é€šè¿‡ä½¿ç”¨unlearningæ“¦é™¤å…¶éƒ¨åˆ†è®­ç»ƒæ•°æ®æ¥ä½¿ç›®æ ‡æ¨¡å‹è¡¨ç°å‡ºåé—¨è¡Œä¸º` | `åé—¨æ”»å‡»`                                   | `é»‘ç›’ï¼ˆï¼‰&&ç™½ç›’ï¼ˆæ¯’å®³è®­ç»ƒé›†ï¼‰éƒ½çŸ¥é“unlearningç®—æ³•`           | `æ•°å­¦å…¬å¼ä¼˜åŒ–æ¨å¯¼è§¦å‘å™¨åŠæ•°æ®é›†ï¼Œç¦»æ•£çš„æ ·æœ¬é€‰æ‹©è½¬æ¢ä¸ºè¿ç»­çš„æ¦‚ç‡` | âŒ                                                          |
| `FedMUA: Exploring the Vulnerabilities of  Federated Learning to Malicious  Unlearning Attacks` | `Jian Chen , Member, IEEE, Zehui Lin, Wanyu Lin ,  Wenlong Shi, Xiaoyan Yin , Member, IEEE, and Di Wang , ` |      `TIFS 2025`       | `exact && approximate unlearning`       | `å‘èµ·æ¶æ„çš„ç‰¹å¾é—å¿˜è¯·æ±‚æ¥æ˜¾è‘—åœ°æ”¹å˜ä¸ç›®æ ‡æ ·æœ¬ç›¸å…³çš„é¢„æµ‹`     | `æ•°æ®ä¸­æ¯’æ”»å‡»`                               | `é»‘ç›’ï¼ˆæœ¬åœ°å®¢æˆ·ç«¯è®­ç»ƒæ•°æ®ä¸­çš„å°æ¯”ä¾‹æ•°æ®ï¼‰`                   | `åˆ©ç”¨å½±å“å‡½æ•°è¯†åˆ«æœ€å…·å½±å“åŠ›çš„æ ·æœ¬ï¼Œæ‰°åŠ¨è¿™äº›æ ·æœ¬ä½¿é è¿‘ç›®æ ‡æ ·æœ¬` | ` https://github.com/ity207/FedMUA`                        |
| `Hard to Forget: Poisoning Attacks on Certified Machine Unlearning` | `Marchant, N. G., Rubinstein, B. I. P., & Alfeld, S.  `      |      `AAAI 2022`       | ` approximate unlearning`               | `å‘èµ·æ¶æ„çš„é—å¿˜è¯·æ±‚ä½¿æ¨¡å‹slow-downï¼ˆè§¦å‘é‡è®­ç»ƒï¼‰`            | `æ•°æ®ä¸­æ¯’æ”»å‡»`                               | `ç™½ç›’è®¾ç½®ä¸­ï¼Œè®¿é—®è‰¯æ€§ç”¨æˆ·çš„è®­ç»ƒæ•°æ®ã€éƒ¨ç½²æ¨¡å‹çš„æ¶æ„å’Œæ¨¡å‹çŠ¶æ€ã€‚ç°ç›’è®¾ç½®ä¸­ï¼Œä»ç„¶æ‹¥æœ‰æ¨¡å‹æ¶æ„çš„çŸ¥è¯†ï¼Œä½†ä¸èƒ½å†è®¿é—®è‰¯æ€§ç”¨æˆ·çš„è®­ç»ƒæ•°æ®å’Œæ¨¡å‹çŠ¶æ€ã€‚` | `PGD-based crafting`                                         | ` https://github.com/ngmarchant/attack-unlearning`         |
| `Learn What You Want to Unlearn: Unlearning Inversion Attacks against Machine Unlearning` | `Hongsheng Huâˆ—, Shuo Wangâ€ , Tian Dongâ€  and Minhui Xueâˆ—`      |       `S&P 2024`       | `exact && approximate unlearning`       | `åªè®¿é—®åŸå§‹å’Œæœªå­¦ä¹ çš„æ¨¡å‹æ¥æ­ç¤ºé—å¿˜æ ·æœ¬çš„ç‰¹å¾å’Œæ ‡ç­¾ä¿¡æ¯`     | `Inversion Attacksï¼ˆå®éªŒè®¾ç½®å­˜åœ¨é—®é¢˜ï¼‰`      | `ç™½ç›’è®¾ç½®ï¼ˆfeatureï¼‰/é»‘ç›’è®¾ç½®ï¼ˆlabelï¼‰ä¸éœ€è¦unlearningç®—æ³•å’Œæ•°æ®é›†ä¿¡æ¯` | `æ¢¯åº¦ä¼°è®¡ä¼˜åŒ–ï¼ˆä½™å¼¦+æ€»å˜åˆ†ï¼‰å¯¹æŠ—æ ·æœ¬ç”Ÿæˆæ£€æµ‹æ¨¡å‹logitå·®å¼‚`   | `https://github.com/TASI-LAB/Unlearning-inversion-attacks` |
| `MACHINE UNLEARNING FAILS TO REMOVE  DATA POISONING ATTACKS` | `Martin Pawelczyk,Jimmy Z. Di, Yiwei Lu Ayush Sekhari, Gautam Kamath Seth Neel` |      `ICLR 2025`       | `approximate unlearning`                |                                                              | `æ•°æ®ä¸­æ¯’æ”»å‡»`                               |                                                              |                                                              |                                                            |
| `UBA-Inf: Unlearning Activated Backdoor Attack with Influence-Driven Camouflage` | `Zirui Huang   Yunlong Maoâˆ—   Sheng Zhong`                   | `USENIX Security 2024` | `exact && approximate unlearning`       | `äº‘ä¸Šæ¨¡å‹è®­ç»ƒä¸­æ¤å…¥æœ‰æ¯’æ ·æœ¬ï¼ŒæŒç»­å­¦ä¹ åœºæ™¯ä¸‹å‘é€unlearningè¯·æ±‚æ¿€æ´»åé—¨` | `åé—¨æ”»å‡»`                                   | `ç°ç›’ï¼šMLaaS çš„äº‘ç«¯æ¨¡å‹ï¼ˆé»‘ç›’ï¼‰æœ‰è¾…åŠ©æ•°æ®é›†æ„é€ å½±å­æ¨¡å‹`     | `åˆ©ç”¨å½±å“å‡½æ•°æ„é€ ä¼ªè£…æ ·æœ¬`                                   | `https://github.com/Huangzirui1206/UBA-Inf/releases`       |
| `ReVeil: Unconstrained Concealed Backdoor Attack on  Deep Neural Networks using Machine Unlearning` | `Manaar Alam, Hithem Lamri, and Michail Maniatakos`          |       `DAC 2025`       | `exact && approximate unlearning`       | `äº‘ä¸Šæ¨¡å‹è®­ç»ƒä¸­æ¤å…¥æœ‰æ¯’æ ·æœ¬ï¼ŒæŒç»­å­¦ä¹ åœºæ™¯ä¸‹å‘é€unlearningè¯·æ±‚æ¿€æ´»åé—¨` | `åé—¨æ”»å‡»`                                   | `é»‘ç›’ï¼Œæ— éœ€è¾…åŠ©æ•°æ®`                                         | `ä¼ªè£…æ ·æœ¬åŠ å…¥é«˜æ–¯å™ªå£°`                                       | `https://github.com/momalab/ReVeil`                        |
| `UNLEARN AND BURN: ADVERSARIAL MACHINE UNLEARNING REQUESTS DESTROY MODEL ACCURACY` | `Yangsibo Huangâˆ— Daogao Liuâˆ— Lynn Chua Badih Ghazi Pritish Kamath Ravi Kumar Pasin Manurangsi Milad Nasr Amer Sinha Chiyuan Zhang` |      `ICLR 2025`       | `approximate unlearning`                | `æäº¤æ¶æ„çš„é—å¿˜ç”³è¯·ï¼ˆä¿®æ”¹æ•°æ®ï¼‰è¯±å¯¼æœåŠ¡å™¨æ¨¡å‹çš„ä¸¥é‡æ€§èƒ½ä¸‹é™` | `æ•°æ®ä¸­æ¯’æ”»å‡»`                               | `é»‘ç›’ && ç™½ç›’ï¼ˆå¯ä»¥è®¿é—®è®­ç»ƒæ•°æ®çš„å­é›† ï¼Œè¿˜å‡è®¾æ”»å‡»è€…çŸ¥é“æ¨¡å‹ä½¿ç”¨çš„å¿˜å´ç®—æ³•--ä¸ç”¨ä¹Ÿå¯ä»¥ï¼‰` | `å¯¹æŠ—æ ·æœ¬ç”Ÿæˆ`                                               | `https://github.com/daogaoliu/unlearning-under-adversary`  |
| `UNLEARNING MAPPING ATTACK: EXPOSING HIDDEN  VULNERABILITIES IN MACHINE UNLEARNING` | `Hao Xuan, Xingyu Li`                                        |                        |                                         |                                                              |                                              |                                                              |                                                              | âŒ                                                          |
| `Exposing Privacy Vulnerabilities in Machine  Unlearning via Distribution-Discrepancy Attacks` |                                                              |                        |                                         |                                                              |                                              |                                                              |                                                              |                                                            |

---

å­˜åœ¨MIAæ”»å‡»ï¼Œå› æ–‡çŒ®è¾ƒæ—©æš‚æ—¶æœªè°ƒç ”

[1]M. Chen, Z. Zhang, T. Wang, M. Backes, M. Humbert, and Y. Zhang, â€œWhen machine unlearning jeopardizes privacy,â€ in Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security, 2021, pp. 896â€“911.

[2]N. Carlini, M. Jagielski, C. Zhang, N. Papernot, A. Terzis, and F. Tramer, â€œThe privacy onion effect: Memorization is relative,â€ Advances in Neural Information Processing Systems, vol. 35, pp. 13 263â€“13 276, 2022.
